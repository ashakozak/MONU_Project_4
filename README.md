# MONU_Project_4
Final Project for Monash University Data Analytics Bootcamp

***

### Scope:

With the lines of truth being blurred between real and fake in the daily news, every day and people becoming more reliant on social media for their news sources - it is more important than ever to be able to differentiate the two for reliable and accurate new sources. In light of this, we have created a model to predict the likelihood that a news article is fake or real<br>

### TOOLS<br>
- MongoDB
- Python
- pandas
- matplotlib
- seaborn
- Scikit learn
- Flask
- Tableau<br><br><br>


### STRUCTURE

_Backend_<br>

Everyone - Create a basic data analysis and upload to github for EDA<br><br>

Jyotsna and Asha backend - cleanse data, modelling, creating csv for analysis -> for user recommendation, need user preference dataset<br>

- Cleaning with MongoDB(?)
- Limitization (remove special characters etc)
- Tokenization after cleaning
- Sentiment analysis - textblob and vader use natural language processing techniques
- Word frequency distribution
- Create a new file for each model
- Asha and Jyotsna can create a machine learning model and create test<br><br>

_Frontend_<br>
- Javascript, HTML, CSS<br>
- Flask API<br>
- Tableau<br>


Priya to create a dashboard, combine tableau with Javascript and connection through Flask
- Create multiple routes or single routes
- User interaction through Java, anything that needs interaction will be in the dashboard
- Combine Tableau wth Javascript and connection through Flask or using Teapot to input data<br>
- Taryn to create analysis in Tableau 
 

### TO COMPLETE 2/11
Asha - to create RNN or LSTM model
Jyotsna - to create RNN or LSTM model model
Priya - Create Flask API
- Gather user input for model
Save model in h5 -> In Python code for flask where it's reading the model and then (as it is used in the test file) preprocessing, limitization, use that code to predict
Taryn - Story/Tableau Visualization template
